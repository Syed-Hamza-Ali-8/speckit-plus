# Implementation Plan: Phase 2 Part 1 - Database Setup

**Branch**: `main` | **Date**: 2025-12-13 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/phase2/part1-database-setup/spec.md`

---

## Summary

Establish a production-ready database foundation for the multi-user Todo web application using SQLModel with Neon Postgres. The implementation creates the Task model with UUID primary key, user ownership, extensible status enum, dual-layer validation (Python + DB), and automatic timestamps. Includes async connection configuration, Alembic migrations, and comprehensive test infrastructure.

---

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: SQLModel 0.0.14+, SQLAlchemy 2.0+, asyncpg, Alembic, pydantic 2.0+
**Storage**: Neon Postgres (serverless) via asyncpg with SSL
**Testing**: pytest + pytest-asyncio (SQLite unit, Neon integration)
**Target Platform**: Linux/Windows server (FastAPI backend)
**Project Type**: Web application backend
**Performance Goals**: N/A for data layer (API layer in Part 3)
**Constraints**: SSL required, async-only connections, Neon-only for integration tests
**Scale/Scope**: Multi-user todo app, single Task entity in Part 1

---

## Constitution Check

*GATE: All checks must pass before implementation.*

| Rule | Status | Notes |
|------|--------|-------|
| Spec exists before code | PASS | `specs/phase2/part1-database-setup/spec.md` approved |
| Phase 2 technology stack | PASS | SQLModel + Neon + FastAPI per constitution |
| Clean Architecture | PASS | Models layer only (Entities) |
| Type hints required | PASS | All functions will have type hints |
| 80% test coverage | PASS | Target in spec success criteria |
| No hardcoded secrets | PASS | Environment variables for DATABASE_URL |

---

## Project Structure

### Documentation (this feature)

```text
specs/phase2/part1-database-setup/
├── spec.md                    # Approved specification
├── plan.md                    # This file
├── research.md                # Technical research findings
├── data-model.md              # Entity definitions
├── quickstart.md              # Setup guide
├── contracts/                 # Interface contracts
│   └── database-contracts.md  # Session and model contracts
├── checklists/                # Implementation tracking
│   └── requirements.md        # Success criteria checklist
└── tasks.md                   # Generated by /sp.tasks (next step)
```

### Source Code (phase2/backend/)

```text
phase2/
└── backend/
    ├── app/
    │   ├── __init__.py
    │   ├── core/
    │   │   ├── __init__.py
    │   │   ├── config.py          # Environment configuration
    │   │   └── database.py        # Async engine and session factory
    │   └── models/
    │       ├── __init__.py        # Model exports
    │       └── task.py            # Task model + TaskStatus enum
    ├── alembic/
    │   ├── versions/
    │   │   └── <timestamp>_create_tasks_table.py
    │   ├── env.py                 # Async migration config
    │   └── script.py.mako         # Migration template
    ├── alembic.ini                # Alembic configuration
    ├── tests/
    │   ├── __init__.py
    │   ├── conftest.py            # Fixtures for both test types
    │   ├── unit/
    │   │   ├── __init__.py
    │   │   └── test_task_model.py # Python validation tests
    │   └── integration/
    │       ├── __init__.py
    │       └── test_task_db.py    # Neon database tests
    ├── pyproject.toml             # Dependencies and config
    ├── .env.example               # Template for environment
    └── .env                       # Local environment (gitignored)
```

**Structure Decision**: Web application backend structure. Models in `app/models/`, core utilities in `app/core/`, tests split by type (unit/integration).

---

## Implementation Phases

### Phase 1: Project Setup
**Goal**: Create project structure and install dependencies

**Files to Create**:
1. `phase2/backend/pyproject.toml` - UV project configuration
2. `phase2/backend/app/__init__.py` - Package init
3. `phase2/backend/app/core/__init__.py` - Core package init
4. `phase2/backend/app/models/__init__.py` - Models package init
5. `phase2/backend/.env.example` - Environment template

**Dependencies**:
```toml
[project]
dependencies = [
    "sqlmodel>=0.0.14",
    "sqlalchemy[asyncio]>=2.0.0",
    "asyncpg>=0.29.0",
    "alembic>=1.13.0",
    "pydantic-settings>=2.0.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=4.0.0",
    "mypy>=1.8.0",
    "aiosqlite>=0.19.0",  # For SQLite async tests
]
```

**Depends On**: None
**Success Criteria**: `uv sync` succeeds, imports work

---

### Phase 2: Configuration Layer
**Goal**: Set up environment-based configuration

**Files to Create**:
1. `phase2/backend/app/core/config.py` - Settings class

**Key Implementation**:
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    database_url: str
    test_database_url: str | None = None

    model_config = {"env_file": ".env", "extra": "ignore"}

settings = Settings()
```

**Depends On**: Phase 1 (project setup)
**Success Criteria**: C5 - Environment variables read correctly

---

### Phase 3: Database Connection
**Goal**: Create async engine and session factory

**Files to Create**:
1. `phase2/backend/app/core/database.py` - Database utilities

**Key Implementation**:
```python
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlmodel.ext.asyncio.session import AsyncSession

def get_async_engine() -> AsyncEngine:
    return create_async_engine(
        settings.database_url,
        echo=False,
    )

async def get_async_session() -> AsyncGenerator[AsyncSession, None]:
    async with async_session_factory() as session:
        yield session
```

**Depends On**: Phase 2 (config)
**Success Criteria**: C1, C2, C3, C4 - Async engine works with SSL

---

### Phase 4: Task Model
**Goal**: Define Task entity with validation

**Files to Create**:
1. `phase2/backend/app/models/task.py` - Task model and enum

**Key Implementation**:
- `TaskStatus` enum with `native_enum=False`
- `Task` model with all 7 fields
- `@field_validator` for title validation
- `CheckConstraint` for database-level validation
- Auto-timestamps with UTC

**Depends On**: Phase 3 (database)
**Success Criteria**: M1-M7, V1-V5 - Model complete with dual validation

---

### Phase 5: Alembic Setup
**Goal**: Configure migrations for async

**Files to Create**:
1. `phase2/backend/alembic.ini` - Alembic config
2. `phase2/backend/alembic/env.py` - Async migration environment
3. `phase2/backend/alembic/script.py.mako` - Migration template

**Key Implementation**:
- Initialize with `alembic init -t async alembic`
- Configure `env.py` for SQLModel metadata
- Add `import sqlmodel.sql.sqltypes` to mako template
- Set naming convention for constraints

**Depends On**: Phase 4 (model)
**Success Criteria**: A1 - Alembic initialized

---

### Phase 6: Initial Migration
**Goal**: Create and verify tasks table migration

**Files to Create**:
1. `phase2/backend/alembic/versions/<timestamp>_create_tasks_table.py`

**Commands**:
```bash
alembic revision --autogenerate -m "create tasks table"
alembic upgrade head
alembic downgrade -1
alembic upgrade head
```

**Depends On**: Phase 5 (Alembic setup)
**Success Criteria**: A2, A3, A4, A5 - Migration reversible with CHECK constraints

---

### Phase 7: Test Infrastructure
**Goal**: Set up pytest fixtures and configuration

**Files to Create**:
1. `phase2/backend/tests/__init__.py`
2. `phase2/backend/tests/conftest.py` - Shared fixtures
3. `phase2/backend/tests/unit/__init__.py`
4. `phase2/backend/tests/integration/__init__.py`

**Key Implementation**:
```python
# conftest.py
@pytest.fixture
async def sqlite_session():
    """SQLite in-memory for unit tests"""
    engine = create_async_engine("sqlite+aiosqlite:///:memory:")
    ...

@pytest.fixture
async def neon_session():
    """Neon Postgres for integration tests"""
    engine = create_async_engine(settings.test_database_url)
    ...
```

**Depends On**: Phase 6 (migration)
**Success Criteria**: T1, T2, T3 - Test isolation achieved

---

### Phase 8: Unit Tests
**Goal**: Test Python validation with SQLite

**Files to Create**:
1. `phase2/backend/tests/unit/test_task_model.py`

**Tests to Implement**:
- Valid task creation
- Empty title rejection (V1)
- Long title rejection (V2)
- Long description rejection (V5)
- Invalid status rejection
- Timestamp auto-population
- Enum extensibility verification (M7)

**Depends On**: Phase 7 (test infrastructure)
**Success Criteria**: T4, T6, T7, T8 - Unit tests pass

---

### Phase 9: Integration Tests
**Goal**: Test database operations with Neon

**Files to Create**:
1. `phase2/backend/tests/integration/test_task_db.py`

**Tests to Implement**:
- CRUD operations (create, read, update, delete)
- CHECK constraint enforcement (V3, V4)
- Index existence verification (M4)
- Timestamp behavior (M5, M6)
- Connection with SSL (C4)

**Depends On**: Phase 8 (unit tests)
**Success Criteria**: T5 - Integration tests pass

---

### Phase 10: Quality Checks
**Goal**: Verify type hints and coverage

**Commands**:
```bash
mypy app/
pytest --cov=app --cov-report=term-missing
grep -r "password\|secret" app/
```

**Depends On**: Phase 9 (integration tests)
**Success Criteria**: Q1, Q2, Q3 - mypy passes, 80%+ coverage, no secrets

---

## Phase Dependencies

```
Phase 1 (Setup)
    │
    ▼
Phase 2 (Config)
    │
    ▼
Phase 3 (Database)
    │
    ▼
Phase 4 (Model)
    │
    ▼
Phase 5 (Alembic)
    │
    ▼
Phase 6 (Migration)
    │
    ├─────────────────┐
    ▼                 ▼
Phase 7 (Test Infra) │
    │                 │
    ├─────────┬───────┘
    ▼         ▼
Phase 8     Phase 9
(Unit)      (Integration)
    │         │
    └────┬────┘
         ▼
    Phase 10 (Quality)
```

---

## Architectural Decisions

### ADR Candidates

1. **Non-Native Enum for TaskStatus**
   - Impact: Long-term (all future status values)
   - Alternatives: Native PostgreSQL ENUM
   - Decision: Use VARCHAR with `native_enum=False`
   - Rationale: Extensibility without migrations

2. **Dual-Layer Validation**
   - Impact: Performance and data integrity
   - Alternatives: Python-only or DB-only
   - Decision: Both layers
   - Rationale: Early failure + ultimate protection

3. **SQLite for Unit Tests**
   - Impact: Test speed vs production parity
   - Alternatives: PGLite, Docker Postgres
   - Decision: SQLite unit + Neon integration
   - Rationale: Speed for unit, parity for integration

**Suggestion**: These decisions are significant but well-documented in research.md. Consider ADR if any becomes contentious:
> "Document reasoning and tradeoffs? Run `/sp.adr non-native-enum-strategy`"

---

## Complexity Tracking

| Concern | Justification |
|---------|---------------|
| Async-only connections | Neon serverless best practice |
| Dual-layer validation | Defense in depth per spec |
| SQLite compatibility | Required by spec for unit tests |

No constitution violations identified.

---

## Risk Analysis

| Risk | Mitigation |
|------|------------|
| SQLite/Postgres syntax differences | Use compatible CHECK constraint syntax |
| Async session management | Use `expire_on_commit=False` |
| Migration naming conflicts | Apply naming convention |
| Connection pooling issues | Neon handles serverless pooling |

---

## Files to Create Summary

| Phase | File Count | Files |
|-------|------------|-------|
| 1 | 5 | pyproject.toml, 4 __init__.py, .env.example |
| 2 | 1 | config.py |
| 3 | 1 | database.py |
| 4 | 1 | task.py (+ update models/__init__.py) |
| 5 | 3 | alembic.ini, env.py, script.py.mako |
| 6 | 1 | migration file |
| 7 | 3 | conftest.py, 2 __init__.py |
| 8 | 1 | test_task_model.py |
| 9 | 1 | test_task_db.py |
| **Total** | **17** | |

---

## Next Steps

1. Run `/sp.tasks` to generate detailed implementation tasks from this plan
2. Execute tasks in dependency order
3. Check off items in `checklists/requirements.md`
4. Run `/sp.implement` to begin implementation

---

**Plan Status**: Complete
**Ready For**: Task generation (`/sp.tasks`)
